国家企业信用公示网爬虫
一、初步设计方案：
    1）总括：
        1、初始采集使用库内原有的企业进行分词
        2、将分词的结果以key_value的形式录入到redis有序集合中
        3、分别给分词打上三个标签 0：未采集 1：已完成采集 2：采集失败
        4、将新采集到的企业放入一个set集合中，分词，并将结果加入到redis数据库zset集合中
        5、取出的分词企业在company_pool中删除掉
        6、将采集得企业信息存入mysql
        7、将采集的企业基本信息组装得到详细信息页面url，请求并且录入数据库


    2）后期优化
        1、可以改为并行的方式，提前是要有足够的代理，异步请求(也可用scrapy写，速度也会提升不少，后面试试)
        2、分布式爬虫，多台机器运行，redis做队列
        3、企业网址池的设定，进行去重优化



    3）存在的问题
        1、无法采集新加入的企业数据（重新遍历不现实）
        2、此网站的cookie获取可能需要重新研究
        3、多维数据获取请求的链接过多，因此只采集基本信息数据
        4、本来想先采集完基本信息后，再去组装详细信息页面，但是其pricid有一个失效时间，因此只能一起去请求
        5、此网站需要加代理才能稳定请求，不然采集一段时间后，无法获取数据,ip就被封了


二、已完成的几个设计：
    1、config.py 主要是一些配置参数
    2、crawl_basicinfo.py 采集基础信息的起始点
    3、crawl_detailinfo.py 采集详细页面的起始地
    4、crawl_spider.py  解析html和传参的地方
    5、cutent.py  分词
    6、db_collect.py 数据库连接
    7、utils.py  发送请求
    8、schedule.py 运行程序



